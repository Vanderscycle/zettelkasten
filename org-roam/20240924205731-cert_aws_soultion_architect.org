:PROPERTIES:
:ID:       cd0fcbf2-addf-48e6-8f15-44b95afd207d
:END:
#+title: cert - AWS Solution Architect

* Home
[[id:9d5c388a-88cd-423c-951b-5e512eae298b][Knowlege base]]
[[id:660c7092-9b98-4fa2-b271-2bbeabe1c249][Programming]]

* Main reference
** Ackronym
Secure File Transfer Protocol (SFTP)
File Transfer Protocol Secure (FTPS)
File Transfer Protocol (FTP)
Set of rules governing how files are moved between server and client running in the application layer (lv7)
Applicability Statement 2 (AS2)
[[https://docs.aws.amazon.com/]]

* Futher learning
** OSI Model
[[https://en.wikipedia.org/wiki/OSI_model][OSI model - Wikipedia]]
** File Transfer Protocol
[[https://en.wikipedia.org/wiki/File_Transfer_Protocol][File Transfer Protocol - Wikipedia]]
* AWS Solution Architect

** TODO Knowledge [6/9]
*** TODO Networking
DEADLINE: <2024-10-16 Wed>
**** VPC
**** VPC endpoints
~VPC endpoints~ in AWS when you want to privately connect your Virtual Private Cloud (VPC) to supported AWS services or other resources without needing an internet gateway, NAT gateway, VPN connection, or ~AWS Direct Connect~. VPC endpoints allow traffic between your VPC and AWS services to stay within the AWS network, enhancing security and reducing the need for public internet access.

**** VPN (on-prem)
~AWS VPN~ establishes a secure and encrypted connection between your on-premises network and your AWS VPC over the public internet

AWS VPN is generally more cost-effective for smaller, less frequent data transfers and is easy to set up without any dedicated physical infrastructure.

**** Direct Connect (on-prem)
AWS Direct Connect is a cloud service solution that allows you to establish a dedicated network connection from your on-premises data center or office to AWS BYPASSING THE INTERNET

has a higher initial cost due to the dedicated line but can be more economical for large-scale data transfers and applications requiring consistent performance.

Speeds up to 1 Gbps, 10 Gbps, and up to 100 Gbps

*** TODO Storage
DEADLINE: <2024-10-06 Sun>
**** EBS ft
**** EFS
**** S3

*** TODO Compute
DEADLINE: <2024-10-06 Sun>
**** EC2
Amazon Elastic Compute Cloud (Amazon EC2) provides on-demand, scalable computing capacity in the Amazon Web Services (AWS) Cloud.

***** instance type
| Instance Type    | Category            | vCPUs | Memory (GiB) | Network Performance | Storage    | Use Case                                            |
|------------------+---------------------+-------+--------------+---------------------+------------+----------------------------------------------------|
| t3.micro         | On-Demand            | 2     | 1            | Up to 5 Gigabit     | EBS only   | General purpose, low-cost, burstable workloads      |
| r6g.large        | Memory Optimized     | 2     | 16           | Up to 10 Gigabit    | EBS only   | Memory-intensive applications                       |
| c6g.large        | Compute Optimized    | 2     | 4            | Up to 12 Gigabit    | EBS only   | Compute-heavy tasks, high-performance computing     |
| p4d.24xlarge     | Accelerated Compute  | 96    | 1152         | 4 x 100 Gigabit     | NVMe SSD  | Machine learning, HPC, and deep learning workloads  |
| i3en.xlarge      | Storage Optimized    | 4     | 32           | Up to 25 Gigabit    | NVMe SSD  | I/O intensive tasks, databases, large storage needs |
| m6i.large        | General Purpose      | 2     | 8            | Up to 12.5 Gigabit  | EBS only   | Balanced compute, memory, and networking            |

***** AMI
An Amazon Machine Image (AMI) is an image that provides the software that is required to set up and boot an Amazon EC2 instance. There are public/private and shared.

***** Key Pair
A key pair, consisting of a public key and a private key, is a set of security credentials that you use to prove your identity when connecting to an Amazon EC2 instance. For Linux instances, the private key allows you to securely SSH into your instance.

***** Lifecycle

#+DOWNLOADED: screenshot @ 2024-10-10 20:10:30
[[file:AWS_Solution_Architect/2024-10-10_20-10-30_screenshot.png]]

***** EBS
used for persistent data
****** volumes
can be attached to the ec2
****** snapshot
point in time saving

***** ELB
To balance the incoming requests to a number of servers

***** autoscaling
Scale based on schedule/cloudwatch alarms/automatic

***** Elastic IP
dedicated AWS IP

***** Launch template
You can use an Amazon EC2 launch template to store instance launch parameters so that you don't have to specify them every time you launch an Amazon EC2 instance. For example, you can create a launch template that stores the AMI ID, instance type, and network settings that you typically use to launch instances. Usefull for autoscaling groups.

#+DOWNLOADED: screenshot @ 2024-10-10 20:17:27
[[file:AWS_Solution_Architect/2024-10-10_20-17-27_screenshot.png]]

***** Cluster placement group

Cluster: same rack
partition: same az
spread: same region

#+DOWNLOADED: screenshot @ 2024-10-10 20:21:14
[[file:AWS_Solution_Architect/2024-10-10_20-21-14_screenshot.png]]

***** Pricing model
| Pricing Model         | Description                                            | Use Cases                                 | Discount             |
|-----------------------+--------------------------------------------------------+-------------------------------------------+----------------------|
| On-Demand             | Pay as you go, no upfront commitment                   | Short-term, spiky workloads               | No discount           |
| Spot                  | Bid for unused capacity at up to 90% discount          | Batch jobs, fault-tolerant workloads      | Up to 90% off         |
| Reserved Instances    | Commitment to 1 or 3 years with upfront payment options| Predictable, long-term workloads          | Up to 75% off         |
| Savings Plans         | Flexible plan based on committed usage (dollars/hour)  | Predictable spend but variable workload   | Up to 72% off         |
| Dedicated Hosts       | Physical server dedicated to your use                  | Compliance, licensing needs               | No discount           |
| Dedicated Instances   | Isolated EC2 instances on dedicated hardware           | Single-tenant environments                | No discount           |
| EC2 Fleet             | Mix of On-Demand, Spot, and Reserved Instances         | Large-scale workloads, cost optimization  | Varies                |

**** EC2 Image builder
EC2 Image Builder is a fully managed AWS service that helps you to automate the creation, management, and deployment of customized, secure, and up-to-date server images.


#+DOWNLOADED: screenshot @ 2024-10-10 20:34:31
[[file:AWS_Solution_Architect/2024-10-10_20-34-31_screenshot.png]]

***** Golden image
An EC2 golden image is a pre-configured Amazon Machine Image (AMI) that serves as a template for launching EC2 instances.

The process is as follow:
- Choose a base image for your customizations.
- Add to or remove software from your base image.
- Customize settings and scripts with build components.
- Run selected tests or create custom test components.
- Distribute AMIs to AWS Regions and AWS accounts.

**** Elastic Network Interface
An elastic network interface is a logical networking component in a ~VPC~ that represents a virtual network card.


#+DOWNLOADED: screenshot @ 2024-10-10 20:40:37
[[file:AWS_Solution_Architect/2024-10-10_20-40-37_screenshot.png]]


decouple the compute from the networking. Each ec2 starts with an ~ENI~ called the primary which cannot be detached. Additional are called secondary eni, can be used for a low budget high availability solution. secondary can be detached.

**** BeanStalk (vercel)
With AWS Elastic Beanstalk, you can quickly deploy and manage applications in the AWS Cloud without worrying about the infrastructure that runs those applications.

AWS version of vercel, trades speed and convenience for costs.

***** Target Audience
Developers and teams looking to deploy web applications quickly without managing underlying infrastructure but still want flexibility and control over the resources.

**** Lightsail (VPS)
Amazon Lightsail is the easiest way to get started with Amazon Web Services (AWS) for anyone who needs to build websites or web applications. It includes everything you need to launch your project quickly

***** Target Audience
Developers, small businesses, or non-technical users who want a simple, low-cost VPS (virtual private server) with minimal AWS knowledge.

**** ECS
Amazon Elastic Container Service (Amazon ECS) is a fully managed container orchestration service that helps you to more efficiently deploy, manage, and scale containerized applications.

***** Launch types
- ec2: still need to manage the ec2 infra
- fargate: aws manages the infra

**** EKS
Amazon Elastic Kubernetes Service (Amazon EKS) is a managed service that eliminates the need to install, operate, and maintain your own Kubernetes control plane on Amazon Web Services (AWS).

***** Worker nodes
****** self-managed
provision ec2 instaces yourself, you install and configure kubernetes bare metal. This also includes the version update
****** managed node group
Automates the provisioning and lifecycle management of ec2 nodes, a more streamlined way to manage lifecycle
****** fargate
AWS manages all

**** ECR
Amazon Elastic Container Registry (Amazon ECR) is a fully managed container registry offering high-performance hosting, so you can reliably deploy application images and artifacts anywhere.

there are 2 kinds public and private.
Can integrate with ~AWS Codecommit~ (aws version of github) and ~AWS codebuild~ (aws version of pipelines)

**** App runner
AWS App Runner is an AWS service that provides a fast, simple, and cost-effective way to deploy from source code or a container image directly to a scalable and secure web application in the AWS Cloud. You don't need to learn new technologies, decide which compute service to use, or know how to provision and configure AWS resources.

An even more streamlined version. push your code or docker image and aws will do the rest

**** Batch
AWS Batch helps you to run batch computing workloads on the AWS Cloud. Batch computing is a common way for developers, scientists, and engineers to access large amounts of compute resources. AWS Batch removes the undifferentiated heavy lifting of configuring and managing the required infrastructure, similar to traditional batch computing software.

#+DOWNLOADED: screenshot @ 2024-10-10 21:02:01
[[file:AWS_Solution_Architect/2024-10-10_21-02-01_screenshot.png]]

**** Lambda
With AWS Lambda, you can run code without provisioning or managing servers. You pay only for the compute time that you consume—there's no charge when your code isn't running.

*** DONE Database
CLOSED: [2024-10-10 Thu 19:53] DEADLINE: <2024-10-06 Sun>
- State "DONE"       from "TODO"       [2024-10-10 Thu 19:53]
**** RDS
Amazon Relational Database Service (Amazon RDS) is a web service that makes it easier to set up, operate, and scale a relational database in the cloud. It provides cost-efficient, resizeable capacity for an industry-standard relational database and manages common database administration tasks. Amazon Aurora is a fully managed relational database engine that's built for the cloud and compatible with MySQL and PostgreSQL.

***** Deployment
****** Single-AZ Database
One region (single AZ), low costs, high latency and no redundancy if the AZ goes down. Can have multiple read replicas
****** Multi-AZ
Multiple AZ, can only have one writer but can have as many reader.
****** Read replicas
create read-only replicas of your db in one or more region (cross region).
****** Aurora global db
replicate data across multiple AWS regions allowing for low latency
****** Serverless
variable workloads + unpredictable traffic patterns
***** Blue/Green
A blue/green deployment copies a production database environment to a separate, synchronized staging environment. By using Amazon RDS Blue/Green Deployments, you can make changes to the database in the staging environment without affecting the production environment.
***** Storage devices
| Storage Type       | Description                                                       | Use Case                                  |
|--------------------+-------------------------------------------------------------------+-------------------------------------------|
| General Purpose SSD| Cost-effective storage that balances price and performance.        | Ideal for most workloads.                 |
| Provisioned IOPS   | High-performance SSD with provisioned IOPS for intensive workloads.| Applications needing consistent IOPS.     |
| Magnetic (Previous)| Older generation storage, slower and cheaper.                     | Not recommended for new deployments.      |
| Aurora Storage     | Scalable, SSD-based storage automatically managed by Aurora.      | Specific to Amazon Aurora RDS.            |

***** Security Optimization
****** sensitive healthcare data
use ~AWS KMS~ to encrypt data at rest to meet secure and compliance regulations
***** Performance Optimization
****** transaction-heavy application
Configure ~AWS RDS~ with provision IOPS storeage for consisten and fast i/o performance

**** RDS Aurora
Amazon Aurora (Aurora) is a fully managed relational database engine that's compatible with MySQL and PostgreSQL.

#+DOWNLOADED: screenshot @ 2024-10-08 20:24:39
[[file:AWS_Solution_Architect/2024-10-08_20-24-39_screenshot.png]]

***** Resiliency optimization
****** Financial institution
Amazon Aurora Global Databases is an ideal recommendation. This feature enables cross-region disaster recovery and data replication, providing a higher level of resilience compared to single-region deployments.

**** RDS Proxy
AWS RDS Proxy is a fully managed, highly available database proxy service that sits between your application and your Amazon RDS or Amazon Aurora databases. It helps improve the scalability, performance, and security of database-intensive applications by managing database connections efficiently.

***** connection pooling
allows for multiple application request to share the same connection
***** Automatic failover
automatically routes connections to the standby database.

***** Resiliency optimization
****** database connectivity issues
proxy can managed database connections and reduce the burden on the database server.

**** redshift
Amazon Redshift is a fast, fully managed, petabyte-scale data warehouse service that makes it simple and cost-effective to efficiently analyze all your data using your existing business intelligence tools. It is optimized for datasets ranging from a few hundred gigabytes to a petabyte or more and costs less than $1,000 per terabyte per year

#+DOWNLOADED: screenshot @ 2024-10-08 21:09:12
[[file:AWS_Solution_Architect/2024-10-08_21-09-12_screenshot.png]]

_analytical operation not transactional_

***** Serverless (cost saving)
provisioned capacity is really expensive, serverless allows us to pay for compute used only. calculated in RPU(16 gb of ram) between 8 -> 512. min 32 rpu for 128 tb+

**** DynamoDB
Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. like rds but for nosql.
***** Standard access table class
***** Infrequent access table class

***** Resiliency optimization
****** high available serverless deployment
Implementing automated snapshots and enabling cross-region snapshot copy in Redshift Serverless are effective strategies for data backup and recovery
****** High demand period
Implement ~AWS dynamoDB~ global tables to provide multi-region, fully replicated data for high avail + disaster recovery.
***** Performance optimization
****** real-time analytics or large dataset
configure ~AWS redshift~ with RA3 nodes to leverage managed storage and high-performance computing for large dataset
***** Cost optimization
****** reduce storage costs
~AWS RedShift Spectrum~ allows users to run queries against exabytes of data in Amazon S3 without having to load and transform any data.

**** DynamoDB accelerator (cache)
DynamoDB Accelerator (DAX) is an in-memory caching service for Amazon DynamoDB that helps improve the performance of read-intensive applications. It acts as a fully managed cache that is tightly integrated with DynamoDB, delivering fast, low-latency data access.

cluster that sits between the request and dynamodb. milli second response but expensive. Scalable up to 10 nodes and fully managed.

**** Opensearch
Amazon OpenSearch Service is a managed service that makes it easy to deploy, operate, and scale OpenSearch, a popular open-source search and analytics engine.

OpenSearch Advantage: OpenSearch is designed for full-text search and handles unstructured data like logs, documents, and text-based data. It can efficiently index, search, and retrieve data using advanced search algorithms.

Use OpenSearch for:

    Full-text search and unstructured data.
    Real-time data analytics and log analysis. (cloudwatch)
    High query throughput with low-latency results.
    Scalable search for large datasets.

#+DOWNLOADED: screenshot @ 2024-10-08 21:31:06
[[file:AWS_Solution_Architect/2024-10-08_21-31-06_screenshot.png]]

***** Serverless
***** ultrawarm
UltraWarm provides a cost-effective way to store large amounts of read-only data on Amazon OpenSearch Service. Standard data nodes use "hot" storage, which takes the form of instance stores or Amazon EBS volumes attached to each node. Hot storage provides the fastest possible performance for indexing and searching new data.

***** Performance optimization
****** requires low-latency
Get the biggest instance you can afford
***** Security optimization
****** Only to be accessible internally
use ~AWS VPC endpoints~. It allows the media company to keep all traffic between their AWS resources and OpenSearch within the AWS network, avoiding exposure to the public internet.

Honestly reminds me of bugsnap

**** ElastiCache
Amazon ElastiCache is a web service that makes it easy to set up, manage, and scale a distributed in-memory data store or cache environment in the cloud.

primarily to cache data between your server and your db (just like redis)

#+DOWNLOADED: screenshot @ 2024-10-08 21:40:31
[[file:AWS_Solution_Architect/2024-10-08_21-40-31_screenshot.png]]

***** Serverless
allows you to scale

***** Redis pub/sub message system
you send a message to a specific channel not knowing who, if anyone, receives it. The people who get the message are those who are subscribed to the channel.
***** Encryption at rest
***** Global datastore
allows for caching globally

***** Cost optimized
****** variable traffic patterns
For predictable workloads, using reserved nodes in ElastiCache for Redis can be more cost-effective than on-demand pricing.
**** MemoryDB
Essentially AWS redis db (cache + db). Can deploy in a cluster, same behavior as ~AWS RDS~

**** DocumentDB
AWS version of MongoDB

#+DOWNLOADED: screenshot @ 2024-10-08 21:51:16
[[file:AWS_Solution_Architect/2024-10-08_21-51-16_screenshot.png]]

***** DocumentDB Global Cluster
you can have secondary clusters in different region

***** Cost optimization
Leverage ~AWS DocumentDB~ with reserved instances to reduce costs for predictable long term usage.

**** keyspaces (cassandra)
AWS managed Apache cassandra

Apache Cassandra is an open-source, distributed NoSQL database management system designed to handle large amounts of structured and unstructured data across many commodity servers, providing high availability with no single point of failure.

use CQL (cassandra query language)

#+DOWNLOADED: screenshot @ 2024-10-08 21:56:57
[[file:AWS_Solution_Architect/2024-10-08_21-56-57_screenshot.png]]

***** Serverless

***** Multi-region replication
can replicate data closest to your users

***** Performance optimized
****** low-latency responses for high velocity data ingestion
use Provisioned IOPS storage

**** Neptune (graphdb)
Amazon Neptune is a fast, reliable, fully managed graph database service

#+DOWNLOADED: screenshot @ 2024-10-08 22:00:10
[[file:AWS_Solution_Architect/2024-10-08_22-00-10_screenshot.png]]

***** serverless

***** Performance optimized
****** low-latency responses for high velocity data ingestion
use Provisioned IOPS storage

**** QLDD (bitcoin/ledger)
Amazon Quantum Ledger Database (Amazon QLDB) is a fully managed ledger database that provides a transparent, immutable, and cryptographically verifiable transaction log owned by a central trusted authority.

***** Performance optimized
****** low-latency responses for high velocity data ingestion
use Provisioned IOPS storage

**** Timestream
Amazon Timestream for LiveAnalytics is a fast, scalable, fully managed, purpose-built time series database that makes it easy to store and analyze trillions of time series data points per day.

#+DOWNLOADED: screenshot @ 2024-10-08 22:04:41
[[file:AWS_Solution_Architect/2024-10-08_22-04-41_screenshot.png]]

***** Dynamic schema
***** Serverless
***** Data lifecycle
Old IOT data isn't as usefull as newer one

***** Performance Optimized
****** handling and querying
AWS Timestream is specifically designed for time-series data and offers a memory store for recent data and a magnetic store for older data

*** DONE Application integration
CLOSED: [2024-10-07 Mon 11:06] DEADLINE: <2024-10-06 Sun>
- State "DONE"       from "TODO"       [2024-10-07 Mon 11:06]
**** Autoscaling
***** Scaling policy
minimum, desired and max instances
- manual: all operations are done manually
- dynamic: 3 types:
****** target tracking policy
This policy adjusts the number of instances in a way that keeps a specific metric, such as CPU utilization or request count, close to a target value.
=ASGAverageCPUUtilization= for an ~AWS EC2~, network =ASGAverageNetworkIn=
****** simple scaling policy
Must set and use ~AWS cloudwatch~ alarm (high usage/low usage). you can control the scaling process e.g. 50-70 add 2 ~EC2~, 85-100 add 5 ~EC2~
****** step scaling policy
caling adjusts the capacity based on step adjustments instead of a target

- scheduled
For predicatable and known loads

***** EC2 specific
you must specify a launch template for the new ~EC2~ to use. e.g. what ~AWS EC2 AMI/size/SG/IAM/EBS volume~ to use.

***** Misc
****** cooldown period
The cooldown period is the amount of time to wait for a previous scaling activity to take effect is called the cooldown period.
****** update EC2 isntance part of a scaling gruppen
Put the instance in Standby mode. Post upgrade, move instance back to InService mode. It will be part of the same auto-scaling group
****** autoscaling termination policy
Termination policy is used to specify which instances to terminate first during scale-in
****** warm pool
 Auto Scaling Warm Pool is a collection of pre-initialized EC2 Instances sitting along with your Auto Scaling Group
****** Hibernation
Hibernation of the Amazon EC2 instance can be used in the =case of memory-intensive applications= or if =applications take a long time to bootstrap=. Hibernation pre-warms the instance, and after resuming it, it quickly brings all application processes to a running state. When an instance is hibernated, the Amazon EC2 instance saves all the content of the instance memory RAM to Amazon EBS volumes. Any root EBS volumes or attached EBS volumes are persisted during hibernation.
****** autoscaling for dbs (data loss) post shutdown
Adding Lifecycle Hooks to the Auto Scaling group puts the instance into a wait state before termination. During this wait state, you can perform custom activities to retrieve critical operational data from a stateful instance. The Default Wait period is 1 hour.

***** Secure architecture
****** EC2 configuration
use ~AWS AMI~ to ensure the same configuration access
***** Cost optimized
****** Burst of usage
using Spot Instances with EC2 Auto Scaling is an effective cost-optimization strategy. Spot Instances allow users to take advantage of unused EC2 capacity at a significantly lower price compared to On-Demand pricing.
**** ELB
Elastic Load Balancing automatically distributes your incoming traffic across multiple targets, such as EC2 instances, containers, and IP addresses, in one or more Availability Zones. It monitors the health of its registered targets and routes traffic only to the healthy targets.

***** Listeners
A listener is a process that checks for connection requests, using the protocol and port that you configure. Before you start using your Application Load Balancer, you must add at least one listener.

***** Target group (which servers request are forwarded too)
Target groups route requests to individual registered targets, such as EC2 instances, using the protocol and port number that you specify.

***** Application load balancer
Supports Http/https and allows for advanced rerouting. e.g. http -> https redirect,
Can allow filtering on GET/POST request or host header rules e.g. blog.website.com -> redirect to ~Target group~ named blog containing dedicated ~AWS EC2~ or path e.g. blog.website.com/store
mostly used for web apps (direct traffic to the right EC2)

***** Network load balancer
Supports TCP, UDP, and TLS

The NLB creates and attaches ~ENIs~ (virtual network interfaces) to the subnets you specify during setup. These ENIs represent the entry points for traffic in each Availability Zone.

***** Misc
****** Cross-zone load balancing
If not enabled it only goes to a specific zone

***** Resilient architecture
****** Handle AZ failures
Configure the ALB to distribute traffic across multiple ~AWS EC2~ instances in different AZ =us-east-1a=, =us-east-1b=. Reminder the ~AWS Subnet~ can only be in one specific ~AZ~

**** API Gateway
Amazon API Gateway enables you to create and deploy your own REST and WebSocket APIs at any scale. You can create robust, secure, and scalable APIs that access Amazon Web Services or other web services, as well as data that’s stored in the AWS Cloud.

- Backend integration complexity
- api management and deployment (versioning)
- request and response transformation
- security and access control ~AWS Cognito~
- Rate limiting and throttling
- Monitoring and analytics
- onboarding and documentation e.g. ~swagger docs~

Supports:
- http api (cheapest)
They are geared toward use cases where speed and cost efficiency are critical, and fewer features are needed.
They provide basic authentication (JWT or OAuth) and routing functionality but lack the deeper feature set of REST APIs.
HTTP APIs are better suited for lightweight, straightforward API designs and serverless functions.
- REST
Request/Response Validation: You can automatically validate API requests and responses, ensuring that the correct data structure is used.
Transformation: You can transform data formats (e.g., from XML to JSON) directly within the API Gateway.
Authentication/Authorization: More advanced security integrations (AWS IAM, Cognito, etc.) are available out of the box.
Caching: Built-in caching mechanisms reduce backend load, but caching increases costs.
Integration Flexibility: REST APIs allow for more complex integration with AWS services.
- websocket

***** Resilient architecture
****** financial sector
~AWS API Gateway~ in conjunction with ~AWS Lambda~ for backend processing is a highly resilient configuration. This allows for automatic scaling to handle varying loads and ensures fault tolerance, as Lambda functions can be automatically triggered from different Availability Zones.

***** Cost optimized
****** http vs rest
choosing HTTP APIs in AWS API Gateway is a prudent decision. HTTP APIs are a more cost-effective option than REST APIs, especially for applications with a high number of API calls. They offer lower cost per million invocations

***** Secure architecture
****** encrypted traffic
Implement SSL/TLD termination on the ELB to ensure encrypted data transmission between clients and the load balancer

**** Appflow
Amazon AppFlow is a fully managed API integration service that you use to connect your software as a service (SaaS) applications to AWS services, and securely transfer data. Use Amazon AppFlow flows to manage and automate your data transfers without needing to write code.

***** Resilient architecture
****** potential connection lost
Use ~AWS S3~ storage as a buffer storage, ensuring data is not lost in case of intermittent connectivity issue.

***** Performant architecture
****** High-volume, real-time data transfer analytics
Integrating ~AWS AppFlow~ with ~Amazon Redshift~ for direct data transfer is an effective strategy for a media company needing high-performance data transfer for real-time analytics.
**** SNS
Amazon Simple Notification Service (Amazon SNS) is a managed service that provides message delivery from publishers to subscribers (also known as producers and consumers). Publishers communicate asynchronously with subscribers by sending messages to a topic

#+DOWNLOADED: screenshot @ 2024-10-06 18:58:27
[[file:AWS_Solution_Architect/2024-10-06_18-58-27_screenshot.png]]

***** First In First Out Topic
You can use Amazon SNS FIFO (first in, first out) topics with Amazon SQS FIFO queues to provide strict message ordering and message deduplication. max 300 messages/seconds

***** Standard Topic
Main issue: messages may show up more than once and out of order. It has high throughput tho

***** Misc
****** Batching
you can batch 1-10 messages per request. max size 256kb but can send 2gb (~S3~ link)

***** Resilient architecture
****** high-volume order processing and notifications
Integrating Amazon SNS with Amazon SQS is a robust strategy for building a resilient notification architecture. This combination allows for decoupling the order processing system from the notification system. When order volumes are high, Amazon SQS can buffer and manage the messages, ensuring that the notification system is not overwhelmed.

***** High-Performing architecture
****** maximize the performance and scalability for broadcasting
Using a fan-out pattern with Amazon SNS topics and multiple Amazon SQS queues is an effective strategy for achieving high performance and scalability when broadcasting alerts to a large audience.

#+DOWNLOADED: screenshot @ 2024-10-07 13:15:50
[[file:AWS_Solution_Architect/2024-10-07_13-15-50_screenshot.png]]

**** SQS
Amazon Simple Queue Service (Amazon SQS) is a fully managed message queuing service that makes it easy to decouple and scale microservices, distributed systems, and serverless applications. Amazon SQS moves data between distributed application components and helps you decouple these components.

***** High-Performing architecture
****** max throughput
Set up ~AWS SQS~ with batch message processing to increase the number of messages processed by actions.

#+DOWNLOADED: screenshot @ 2024-10-06 19:18:12
[[file:AWS_Solution_Architect/2024-10-06_19-18-12_screenshot.png]]

*****  Standard queues
Standard queues ensure at-least-once message delivery, but due to the highly distributed architecture, more than one copy of a message might be delivered, and messages may occasionally arrive out of order.

***** FIFO
FIFO (First-In-First-Out) queues have all the capabilities of the standard queues, but are designed to enhance messaging between applications when the order of operations and events is critical, or where duplicates can't be tolerated.

***** Dead letter queues
Amazon SQS supports dead-letter queues (DLQs), which source queues can target for messages that are not processed successfully. DLQs are useful for debugging your application because you can isolate unconsumed messages to determine why processing did not succeed.

***** Visibility timeout
When a consumer receives a message from an Amazon SQS queue, the message remains in the queue but becomes temporarily invisible to other consumers. This temporary invisibility is controlled by the visibility timeout
***** Misc
****** ApproximateNumberOfMessagesVisible
pproximateNumberOfMessagesVisible describes the number of messages available for retrieval. It can be used to decide the queue length.
****** ApproximateNumberOfMessagesNotVisible
ApproximateNumberOfMessagesNotVisible measures the number of messages in flight.

***** Resilient architecture
****** enhance resilience of order processing system
Enable the Dead letter Queue to manage undeliverable events

**** AWS MQ
Amazon MQ is a managed message broker service that makes it easy to set up and operate message brokers in the cloud. Amazon MQ provides interoperability with your existing applications and services.

| Resource type              | Amazon SNS | Amazon SQS | Amazon MQ |
|----------------------------+------------+------------+-----------|
| Synchronous                | No         | No         | Yes       |
| Asynchronous               | Yes        | Yes        | Yes       |
| Queues                     | No         | Yes        | Yes       |
| Publisher-subscriber messaging | Yes     | No         | Yes       |
| Message brokers            | No         | No         | Yes       |

***** Performant architecture
****** high-volume/real-time transaction data
use ~AWS MQ~ with dedicated broker instances to provide dedicated resources for high traffic

**** AWS Eventbridge
Amazon EventBridge is a serverless event bus service that makes it easy to connect your applications with data from a variety of sources. EventBridge delivers a stream of real-time data from your own applications, software-as-a-service (SaaS) applications, and AWS services and routes that data to targets such as AWS Lambda.

#+DOWNLOADED: screenshot @ 2024-10-06 20:08:41
[[file:AWS_Solution_Architect/2024-10-06_20-08-41_screenshot.png]]

***** High-Performing architecture
****** processing high-volume, real-time events
real-time analytics platform dealing with a large volume of events, using ~AWS EventBridge~ in conjunction with ~AWS Lambda~ allows for efficient and scalable event processing

***** Resilient architecture
****** enhance resilience of order processing system
using the default event bus, Enable the Dead letter Queue to manage undeliverable events

**** AWS SES (email)
Amazon Simple Email Service (SES) is an email platform that provides an easy, cost-effective way for you to send and receive email using your own email addresses and domains.

***** Verified identies
Same thing as supabase + resend integration to reduce span
***** Misc
****** Solution that ensures high deliverability rates and efficient handling of bounce and complaint notifications.
A dedicated IP pool allows the firm to manage its own email sending reputation, which is crucial for ensuring that their emails are not marked as spam and that they reach their intended recipients

**** AWS Step functions
AWS Step Functions is a serverless orchestration service that lets you integrate with AWS Lambda functions and other AWS services to build business-critical applications.
AWS Step Functions coordinate application components using visual workflows.

***** Resilient architecture
****** In a transaction system
Use the built-in retry policies

***** High-Performing architecture
****** Parallel
You can use parallel state to process multiple files/process concurently

***** Cost optimized
****** filter events
sing AWS EventBridge with a default event bus and applying filtering rules, the application can ensure that only relevant events are processed

#+DOWNLOADED: screenshot @ 2024-10-06 19:59:01
[[file:AWS_Solution_Architect/2024-10-06_19-59-01_screenshot.png]]

***** Misc
****** step func vs SQS
 Although Amazon SQS and Step Functions both help in some sort of orchestration. Amazon SQS doesn’t have the capability to let you track all the tasks and events of your application.

**** Workflow services
Use step function most of the time unless you require external signal to interact within the process, or start child processes.

Need to use python, go, javascript, etc.

***** Resilient architecture
****** Complex system
By incorporating parallel processing of transactions in AWS Simple Workflow Service, the financial services company can ensure that the failure or delay of one task does not halt or significantly impact the entire process.

**** Maanged Workflow for Apache Airflow (MWAA)
Amazon Managed Workflows for Apache Airflow is a managed orchestration service for Apache Airflow that you can use to setup and operate data pipelines in the cloud at scale.

***** Resilient architecture
****** enhance resilience
By configuring AWS MWAA to use ~Amazon RDS~ Multi-AZ deployments for its metadata database, the Solutions Architect can ensure that the database, which is central to the operation of Apache Airflow, remains highly available and resilient to failures.
*** DONE Data ML
CLOSED: [2024-09-30 Mon 12:59] DEADLINE: <2024-09-29 Sun>
- State "DONE"       from "TODO"       [2024-09-30 Mon 12:59]
**** kinesis (Data ingestion)
- video streams
Inputs (video's feed)
Output can be ~AWS Rekognition~, ~AWS S3~, ~AWS Sagemaker~
- data streams
Inputs any data stream
You can use Amazon Kinesis Data Streams to collect and process large streams of data records in real time.
Outputs can be ~AWS EC2~, ~AWS Lambda~, ~AWS EMR~, ~Kinesis Data Analytics~ (mostly other compute)
- data firehose
Inputs any data stream
Outputs can be ~AWS S3~, ~AWS Redhshift~. The main difference between that and ~data streams~ is that the outputs are data repositories
- data analytics (queries on the data before it hits storage)
**** Kafka
Amazon Managed Streaming for Apache Kafka (Amazon MSK) is a fully managed service that makes it easy for you to build and run applications that use Apache Kafka to process streaming data. High data ingestion, processing and delivery. Can be serverless.
~Apache Kafka~ is a distributed queue system decoupling producer and consumers. Queues are split into partitions which can be consumed using the partition key. Partitions hosted on a machine are called brokers
**** glue ETL
~AWS Glue~ is a serverless data integration service that makes it easy for analytics users to discover, prepare, move, and integrate data from multiple sources. You can use it for analytics, machine learning, and application development.
Defined datastore, create a crawler, populates glue data catalog
**** Elastic Map Reduce (EMR)
Amazon EMR is a managed cluster platform that simplifies running big data frameworks like Apache Hadoop and Apache Spark on AWS.  There is ~EMR Studio~ which allows for collaboration
~Apache Hadoop~ stores data accross several nodes in a cluster, process data accross multiple nodes, and then stores the results
~Apache Spark~ is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters.
Can be hosted on ~EC2~, ~EKS~ or ~serverless~
**** glue Databrew
NoCode application of ~AWS Glue~
**** lake formation
AWS Lake Formation is a managed service that makes it easy to set up, secure, and manage your data lakes. Lake Formation helps you discover your data sources and then catalog, cleanse, and transform the data. Any source can be ~nosql~, ~s3~, ~redshift~, ~sql~
**** Athena
Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL. Athena is serverless, so there is no infrastructure to setup or manage, and you pay only for the queries you run.
**** Quicksight
Serverless data visuliaztion engine for interactive dashboarding pulling data from:
- s3
- athena
- RDS
- redshift
- aurora
- glue
**** Sagemaker
Build, train, and deploy machine learning models (image classification, object detection, regression, clustering/grouping, etc.) at scale.
[[https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html][Algos - Amazon SageMaker]]
Process:
- Data ingestion (~s3~ bucket)
- Data preparation and exploration
- Model training
- Model Evaluation + parameter tuning
- Model deployment
AWS process:
Pull data stored in ~s3~ using ~AWS Glue~ for ETL into sagemaker for:
- exploratory data analysis
- data cleaning
- building model
- deploy model
**** rekognition
AWS ML service that analyze and intrepret images and videos. Can be used for content moderation. Comes with a probability score
AWS process:
- user upload image from website to s3
- trigger's ~AWS lambda~
- AWS rekognition dumps metadata into ~AWS dynamoDB~
- low probability images can leverage ~AWS augmented AI~ for human to review machine learning predictions
**** Polly
Turn text into speech.
AWS process:
[[file:~/Documents/zettelkasten/data/image/cert/satty-20240925-14:02:00.png][polly]]
**** Lex
AWS chatbot (think alexa)
provides advanced deep learning functionalities of automatic speech recognition (ASR) for converting speech to text and natural language understanding (NLU) to recognize the intent of the text?
**** Comprehend
Natural language processing and text analysis.
***** Personally identifiable information e.g. credit card numb
**** forecast(NoCode)
Delivers forecasts on time series data (sales, website traffic, etc.)
**** Augmented AI
Integrate human reviewers to review AI's prediction.
Can be used for ~AWS Trasnlate~ for low confidence translation
~AWS rekognition~ for low confidence image label/sentiment/etc.

~AWS Mechnical Turk (MTurk)~ a virtual workforce that is paid per assignemtn to do this if you don't have the manpower to man A2I.
**** Fraud detector (NoCode)
Build, deploy, manage fraud detection model. Usefull for payment fraud detection.
[[file:~/Documents/zettelkasten/data/image/cert/fraudDectection.png][Fraud detection]]
**** transcribe
Speech to text. The opposite of ~AWS polly~
**** translate
AWS Google translate. Usefull for a single chatbot using multiple languages.
Can upload custom terminology to augment the translator.
**** textract
extract text from scanned forms.
Can extract:
- text
- forms
- tables
- signatures

*** DONE Migration/transfer
CLOSED: [2024-09-30 Mon 11:25] DEADLINE: <2024-09-29 Sun>
- State "DONE"       from "TODO"       [2024-09-30 Mon 11:25]
**** Intro
To migrate from on prem to AWS
- assess and create inventory
- categorize the items
- determine AWS cloud services
- plan migration
- execute the migration
**** migration hub
AWS Migration Hub (Migration Hub) provides a single place to discover your existing servers, plan migrations, and track the status of each application migration.
Connect migration tools to migration hub, migrate using the tools, and group servers as applications
***** Cost Optimization
****** During the migration
By using ~AWS Migration Hub~ to monitor the migration progress, the Solutions Architect can identify any delays or issues that might lead to extended migration timelines and, consequently, higher costs.
****** Assess on-premise infrastructure
Leverage ~AWS Apllication Discovery~ to identify over-provisioned resouces and recommend rightsizing before migration to AWS.
***** Security optimization
****** Security of sensitive data
Implement ~AWS IAM~ roles + policies to control access to ~AWS Migration Hub~ and resources being migrated.
***** Reliability/Resilience optimization
****** Critical continuity
By using ~AWS Migration Hub~ to plan and execute a sequential migration, starting with the most critical application tiers, the Solutions Architect can ensure that the most essential services remain available during the migration process.
**** application discovery service
~AWS Application Discovery Service~ helps you plan your migration to the AWS cloud by collecting usage and configuration data about your on-premises servers and databases
The ~AWS Application Discovery Agent~ (Discovery Agent) is software that you install on on-premises servers and VMs targeted for discovery and migration. Has to be installed on every server
~Application Discovery Service Agentless~ Collector(Agentless Collector) is a virtual appliance that you install in your on-premises VMware environment. Can only be used for =VMware environments=
The data gathered will be stored in an ~AWS S3 bucket~ and can be access by ~AWS Athena~ ~AWS migration hub~ ~AWS database migration services~
***** Performance Optimization
****** on-premises infra bottleneck
~AWS Application discovery~ can be used to identify underutilized resources and optimize for performance
****** post migration
implement ~AWS Global Accelerator~ to optimize network paths and improve game server performance post migration
***** Security Optimization
****** AWS Application services
store ~AWS Application discovery~ service gathered data into ~AWS S3~ with encryption enabled by ~AWS KMS~
**** application migration service
AWS Application Migration Service ~AWS MGN~ is a highly automated lift-and-shift (rehost) solution that simplifies, expedites, and reduces the cost of migrating applications to AWS.
Setup service, import inventory, replicates and syncs the data, test, and cutover
***** Security Optimization
****** Sensitive data
Use ~AWS KMS~ to encrypt data before migrating it with ~AWS MGN~. Ensures data is protect both in transit and at rest
**** database migration service
AWS Database Migration Service (AWS DMS) is a cloud service that makes it possible to migrate relational databases, data warehouses, NoSQL databases, and other types of data stores.
Allows for schema conversion e.g. mySql to postgresQL ~DMS schema conversion tool~
replication task (on prem source endpoint -> target AWS cloud endpoint) using DMS EC2 replication instance
- Full load (requires downtime)
- Full load + CDC
- CDC only
Allows for continuous data
***** Performance Optimization
****** Want best
Consider the use case ~AWS aurora~ for sql, ~AWS redshift~ for data warehousing, ~AWS DynamoDB~ for k/v + noSql
***** Reliability/Resilience
****** high resilience/fault tolerence during and after migration process
~AWS DMS~ with multi-az deployment for target db
***** Cost Optimization
****** startup unsure about AWS db costs
Use ~AWS Aurora serverless~ to automatically scale capacity and minimize costs > ~AWS RDS~ w/ reserved instance pricing model
**** Elastic disaster recovery
AWS Elastic Disaster Recovery (AWS DRS) minimizes downtime and data loss with fast, reliable recovery of on-premises and cloud-based applications =GCP= =Azure= using affordable storage, minimal compute, and point-in-time recovery. Can also be used on AWS fro region to region
Main issue without ~AWS EDR~ for on-prem services expensive (requires duplicate infra on stby), maintenance + skilled personel intensive.
Data is replicated from on-prems to AWS, using an ~AWS EC2~ and stores it on ~AWS EBS Volumes~
Allows for real time sync and point-in-time recovery, automated DR drills
***** Cost Optimization
****** network design strategy
AWS Direct Connect establishes a dedicated network connection between the company's infrastructure and AWS, which can significantly reduce data transfer costs during disaster recovery operations.
****** EBS
~AWS EBS~ with snapshot lifecycle policies to automate creation/deleition + costs
****** network design
~AWS Direct Connect~ to establish a dedicated network connection, reducing data transfer costs during disaster recovery operations
***** Performance Optimization
****** Minimal downtime and quick recovery (data storage)
Leverage ~AWS EDR~ and ~AWS FSx Lustre~
**** AWS Mainframe modernization
AWS Mainframe Modernization helps you modernize your mainframe applications to AWS managed runtime environments. It provides tools and resources to help you plan and implement migration and modernization.
You can =refactor= using ~AWS blu age~ or =replatform= with ~AWS Micro focus~
***** Cost Optimization
****** reduce costs by modernizing their legacy mainframe systems
Migrate the mainframe applications to a serverless architecture using ~AWS Lambda~
***** Reliability/Resilience
implement ~AWS mainframe modernization~ with multi-az deployment for migrated applications
**** Datasync (Mass data migration)
AWS DataSync is an online data transfer and discovery service that simplifies data migration and helps you quickly, easily, and securely transfer your file or object data to, from, and between AWS storage services.
An agent must be deployed on prem then ~AWS DataSync discovery~ provides recommendations
Can also be used to transfer large amount of data between AWS region
***** Cost Optimization
****** updates only
Implement incremental data transfer with ~AWS Datasync~ to reduce volume of data transferred
***** Performance Optimization
****** During transfer
~AWS DataSync~ ability to perform parallel transfers and multipart uploads to Amazon S3 is particularly beneficial for large files.
**** AWS Transfer Family ()
AWS Transfer Family is a secure transfer service that enables you to transfer files into and out of AWS storage services.
Can be internal and also connect cloudwatch to check for what files get moved
AWS Transfer Family functions somewhat like an external drive in the sense that it allows external clients, partners, or users to access files in Amazon S3 using familiar protocols like SFTP, FTPS, or FTP
***** Security Optimization
****** strict security protocol
~AWS transfer family~ with MDA for secure access control during file transfer
**** AWS Snow family
The AWS Snow Family is a service that helps customers who need to run operations in austere, non-data center environments, and in locations where there's no consistent network connectivity. Can handle petabytes depending on the snow.
Snowball edge
snowcone
snowball: CPU optimized 104vCPU, Storage optimized 210TB NVME/80TB HDD
snowmobile: exabyte scale data migration
***** Cost Optimization
****** Large scale data transfer (several petabytes)
Use ~AWS Snowmobile~ for one-time, large-scale data transfer

*** DONE Management/Governance
CLOSED: [2024-10-02 Wed 20:41] DEADLINE: <2024-09-29 Sun>
- State "DONE"       from "TODO"       [2024-10-02 Wed 20:41]
**** cloudformation
***** drift detection
AWS CloudFormation Drift Detection can be used to detect changes made to AWS resources outside the CloudFormation Templates. AWS CloudFormation Drift Detection only checks property values explicitly set by stack templates or by specifying template parameters.

***** Parameters
Allow users to input custom values when creating or updating a stack, making templates more flexible and reusable.
#+BEGIN_SRC yaml
Parameters:
  InstanceTypeParameter:
    Type: String
    Default: t2.micro
    AllowedValues: [t2.micro, m1.small, m1.large]
    Description: Enter instance type (e.g., t2.micro)
#+END_SRC

***** Mappings
Define sets of static values that are mapped to keys, which can be referenced within the template.
#+BEGIN_SRC yaml
Mappings:
  RegionToAMI:
    us-east-1:
      AMI: "ami-0ff8a91507f77f867"
    us-west-2:
      AMI: "ami-0a8e758f5e873d1c1"
#+END_SRC

***** Conditions
Define conditional logic based on input parameters or other conditions, controlling when certain resources are created or updated within the stack.
#+BEGIN_SRC yaml
Conditions:
  CreateProdResources: !Equals [ !Ref EnvType, prod ]
#+END_SRC

***** Resources
Define the AWS resources that make up your stack.
#+BEGIN_SRC yaml
Resources:
  MyEC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      InstanceType: !If [CreateProdResources, "m1.small", !Ref InstanceTypeParameter]
      ImageId: !FindInMap [RegionToAMI, !Ref "AWS::Region", AMI]
#+END_SRC

***** Outputs
Define values that are returned by the stack once it's created or updated.
#+BEGIN_SRC yaml
Outputs:
  WebsiteURL:
    Description: URL of the website
    Value: !GetAtt WebsiteBucketWebsiteURL
#+END_SRC

***** cfn-init
helper script is used to retrieve and interpret resource metadata from the =AWS::CloudFormation::Init= key.

***** cfn-hup
helper script checks for any updates to the metadata. If there are any changes, it executes custom hooks.

***** cfn-signal
helper script can be used to signal CloudFormation to indicate if software or application is successfully updated on an Amazon EC2 instance.

***** cfn-get-metadata
helper script helps to retrieve metadata

***** StackSets
AWS CloudFormation StackSets extends the capability of stacks by allowing you to create, update, or delete stacks across multiple accounts and AWS Regions with a single operation.

***** Nested stacks
As your infrastructure grows, common patterns can emerge in which you declare the same components in multiple templates.

terraform modules

***** Change sets
Change sets allow you to preview how proposed changes to a stack might impact your running resources

**** Cloud Development Kit (CDK)
Because writting cloudformation template by hand is a pain.

The AWS Cloud Development Kit (AWS CDK) is an open-source software development framework for defining cloud infrastructure in code and provisioning it through AWS CloudFormation.

=cdk synth= synthetise the cloudformation templates
=cdk deploy= deploys the formations to AWS.
**** Cloudwatch
Amazon CloudWatch monitors your Amazon Web Services (AWS) resources and the applications you run on AWS in real time. You can use CloudWatch to collect and track metrics, which are variables you can measure for your resources and applications.

The CloudWatch home page automatically displays metrics about every AWS service you use. You can additionally create custom dashboards to display metrics about your custom applications, and display custom collections of metrics that you choose.

You can collect system-level metrics from on-prems and view alongside AWS metrics. using ~AWS Cloudwatch agent~

***** Metric
data such as latency, cpu load, etc. from your applications

***** Alarms
Alarms from metrics. Usefull for custom alarms which can be fed into ~AWS SNS~, then you can trigger a ~AWS Lambda~. Services like ~AWS autoscaling~ works out of the box.

***** Logs
All the logs generated from your application

***** Events
usefull for usage with ~AWS EventBridge~

**** x-ray
~AWS X-Ray~ is a service that collects data about requests that your application serves, and provides tools that you can use to view, filter, and gain insights into that data to identify issues and opportunities for optimization.

**** AWS Health Dashboard
General dashboard informing AWS customers about ongoing issues that AWS services/region are experiencing.

**** Prometheus
Amazon Managed Service for Prometheus is a serverless, Prometheus-compatible monitoring service for container metrics that makes it easier to securely monitor container environments at scale.

Open source solution for ~AWS Cloudwatch~. Collects your metrics

**** Grafana
Amazon Managed Grafana is a fully managed and secure data visualization service that you can use to instantly query, correlate, and visualize operational metrics, logs, and traces from multiple sources.

Open source solution for advanced analytics and visualization platform.

**** Trusted advisor
Trusted Advisor draws upon best practices learned from serving hundreds of thousands of AWS customers. Trusted Advisor inspects your AWS environment, and then makes recommendations when opportunities exist to save money, improve system availability and performance, or help close security gaps.

Mostly recommendations (but you have to pay for them)

The key words is that its across cost savings, performance, security and fault tolerance

**** Launch Wizard
AWS Launch Wizard helps you reduce the time that it takes to deploy well knows application (~AWS EKS~, ~SAP~, ~MS Active Dir~)and domain-controller solutions to the cloud.

**** Compute Optimizer
AWS Compute Optimizer recommends optimal AWS compute resources for your workloads.

~AWS EC2~, ~AWS EBS~, Fargate

**** AWS Organization
AWS Organizations helps you centrally manage and govern your environment as you grow and scale your AWS resources. Using Organizations, you can create accounts and allocate resources, group accounts to organize your workflows, apply policies for governance, and simplify billing by using a single payment method for all of your accounts.

You can only have one root and one management account. The later creates the policies, invites organizations, applying policies, etc.

***** Organization Units
An AWS Organization has the below hierarchy of Organizational Units (OUs): Root -> organization_OU (e.g. company a) -> Dev_OU
Project_OU is attached to an SCP that prevents users from deleting VPC Flow Logs. Dev_OU has an SCP that allows the action of "ec2: DeleteFlowLogs".

***** Service Control Policies (SCP)
Service control policies (SCPs) are a type of organization policy that you can use to manage permissions in your organization. SCPs offer central control over the maximum available permissions for the IAM users and IAM roles in your organization. Can apply to a specific acct, org, etc.

SCPs do not grant permissions to the IAM users and IAM roles in your organization. Only defines what you are allowed todo within that account. e.g. in the dev_OU you shouldn't be spinning large ec2.

**** Control tower
AWS Control Tower is a service that enables you to enforce and manage governance rules for security, operations, and compliance at scale across all your organizations and accounts in the AWS Cloud.

best thought as an AWS acct orchestrator

***** Landing Zone
A landing zone is a well-architected, multi-account environment that's based on security and compliance best practices. Creates two AWS Organizations organizational units (OUs): Security, and Sandbox (optional), contained within the organizational root structure. Creates or adds two shared accounts in the Security OU: the Log Archive account and the Audit account.

***** Controls/guardrails
 is a high-level rule that provides ongoing governance for your overall AWS environment. It's expressed in plain language. Three kinds of controls exist: preventive, detective (reports but doesn't stop you), and proactive(does not provision). It uses ~AWS Org SCP~
Detective controls detect specific events when they occur and log the action in CloudTrail.

***** Account Factory
An Account Factory is a configurable account template that helps to standardize the provisioning of new accounts with pre-approved account configurations.

**** System manager
Use AWS Systems Manager to organize, monitor, and automate management tasks on your AWS resources.

***** Operation manager
Use Incident Manager, a capability of AWS Systems Manager, to manage incidents occurring in your AWS hosted applications.

***** Application manager
 Application Manager aggregates operations information from multiple AWS services and AWS Systems Manager capabilities to a single AWS Management Console.

***** Parameter Store
key/value pair for secret or
b**** service catalog

***** Change manager
Simplify how your team requests, approves, implements, and reports on operational changes. Manage changes to your application configuration and infrastructure, both in AWS and on premises. Can specify blackout days (no changes)

***** Node Management
AWS Systems Manager provides the following capabilities for accessing, managing, and configuring your managed nodes. A managed node is any machine configured for use with Systems Manager in a hybrid and multicloud environment.

Feels like terraform should control said changes. I do see it being usefull for DB changes.

**** Service Catalog
AWS Service Catalog enables IT administrators to create, manage, and distribute portfolios of approved products to end users, who can then access the products they need in a personalized portal. Typical products include servers, databases, websites, or applications that are deployed using AWS resources

**** License Manager
~AWS License Manager~ indeed enables organizations to track both ~AWS-provided licenses~ and custom licenses (3rd party) procured independently. It provides visibility into license usage, helps in controlling usage to ensure compliance with licensing terms, and offers features like License Manager rules to set up licensing rules.

does not automatically purchase or allocate additional licenses when usage exceeds predefined thresholds.

**** Proton
AWS Proton creates and manages standardized infrastructure and deployment tooling for developers and their serverless and container-based applications.

I dare say that terraform modules does that

**** Resource group and tag manager
AWS Resource Explorer is a resource search and discovery service. With Resource Explorer, you can explore your resources, such as Amazon Elastic Compute Cloud instances, Amazon Kinesis streams, or Amazon DynamoDB tables, using an internet search engine-like experience.

**** Resilience hub
AWS Resilience Hub helps you proactively prepare and protect your AWS applications from disruptions. AWS Resilience Hub provides resiliency assessment and validation to help you identify and resolve issues before releasing applications into production.

Acts as an overseer

***** Recovery point objective (RPO)
The maximum acceptable amount of time since the last data recovery point. This determines what is considered an acceptable loss of data between the last recovery point and the interruption of service.

***** Recovery time objective (RTO)
The maximum acceptable delay between the interruption of service and restoration of service. This determines what is considered an acceptable time window when service is unavailable.

**** Resource Explorer
Simply search and discovery of AWS resources accross regions

**** Resource Access Manager

*** DONE Security
CLOSED: [2024-10-06 Sun 16:46] DEADLINE: <2024-09-29 Sun>
- State "DONE"       from "TODO"       [2024-10-06 Sun 16:46]
**** IAM
AWS Identity and Access Management (IAM) is a web service for securely controlling access to AWS services. With IAM, you can centrally manage users, security credentials such as access keys, and permissions that control which AWS resources users and applications can access.
Least Privilege Principle

***** User
An IAM user is an entity that you create in your AWS account. The IAM user represents the human user or workload who uses the IAM user to interact with AWS resources. A IAM user consists of a name and credentials.

***** Group
An IAM user group is a collection of IAM users.

***** Role
An IAM role is an IAM identity that you can create in your account that has specific permissions.  a role is intended to be assumable by anyone who needs it.

***** Policy
Dictate permission a user has access to.

**** IAM Identity Center (SSO)
IAM Identity Center provides one place where you can create or connect workforce users and centrally manage their access to all of their AWS accounts and applications. Workforce users benefit from a single sign-on experience and can use the AWS access portal to find all their assigned AWS accounts and applications.

**** Cognito
Amazon Cognito handles user authentication and authorization for your web and mobile apps. With user pools, you can easily and securely add sign-up and sign-in functionality to your apps.

***** User pool
An Amazon Cognito user pool is a user directory for web and mobile app authentication and authorization. A user pool adds layers of additional features for security, identity federation, app integration, and customization of the user experience.

The user are given a token.

***** Identity pool
An Amazon Cognito identity pool is a directory of federated identities that you can exchange for AWS credentials. Identity pools generate temporary AWS credentials for the users of your app

Allows for the user to access AWS resources (upload to an S3)

**** Directory Service
MS Active Dir: Directory service created by microsoft which enable administrator to managed permissions + access to different services/applications.

AWS Directory Service provides multiple ways to set up and run Microsoft Active Directory with other AWS services such as Amazon EC2, Amazon RDS for SQL Server, FSx for Windows File Server, and AWS IAM Identity Center.

TL;DR AWS Managed Microsoft AD managed accross multiple availability zones.

***** Simple AD
Does not integrate with on-prems but easy integration
***** Managed Ms AD
actual implementation, on AWS, of MS AD
***** AD Connnector
if you have ms AD on prems you don't have to get a duplicate

**** Verified permissions
Amazon Verified Permissions is a scalable, fine-grained permissions management and authorization service for custom applications built by you.
attribute-based access control (ABAC) to manage permission as opposed to Role-baed access control (RBAC) used in k8s

***** Differences between IAM
IAM Permissions are for AWS resources (e.g., S3, EC2, Lambda).
AWS Verified Permissions are for application-level access control, extending beyond AWS services to control actions within an application.

**** CloudTrail
With AWS CloudTrail, you can monitor your AWS deployments in the cloud by getting a history of AWS API calls for your account, including API calls made by using the AWS Management Console, the AWS SDKs, the command line tools, and higher-level AWS services. You can also identify which users and accounts called AWS APIs for services that support CloudTrail, the source IP address from which the calls were made, and when the calls occurred.

TL;DR: audit trails, stores for 30days, longer needs to go in a s3 bucket and query through elastic search
Cloudtrail can trigger ~AWS CloudWatch~ alarms which then generates a ~eventbrdige/sns~ which can lead to an ~lambda~

**** AWS Config
AWS Config provides a detailed view of the resources associated with your AWS account, including how they are configured, how they are related to one another, and how the configurations and their relationships have changed over time.

Great for auditing the changes to one's resource/app. Analogy librarian keeping track of the state and status of books throughout their lifetime

**** Artifacts
~AWS Artifact~ is a web service that enables you to download AWS security and compliance documents such as ISO certifications and SOC reports. Works for GDPR.

You can download the report and submit to the auditor directly

**** AWS GuardDuty
Amazon GuardDuty is a fully managed and advanced threat detection service providing broad protection to AWS Accounts and workloads. It helps to identify threats like attacker reconnaissance, instance compromise, account compromise, and bucket compromise.

Uses machine learning and threat inteligence. Collects logs such as ~cloudtrail~, ~vpc flow logs~, ~dns logs~ which then can trigger a ~lambda~.
If something happens, it generates a finding and gives it a severity score.
You can give it a trusted IP list (safe IPs) and a threat IP list (generated from org or taken elsewhere)

***** GuardDuty detection categories
- reconnainssance
- instance compromise
- account compromise
- bucket compromise

**** Inspector
Amazon Inspector is a security vulnerability assessment service that helps improve the security and compliance of your AWS resources. Amazon Inspector automatically assesses resources for vulnerabilities or deviations from best practices, and then produces a detailed list of security findings prioritized by level of severity.

You must specify the resources to scan (assessment target) _Focused on the workloads_
Check for the following:
- package vulnerability
- code vulnerability
- network reachability

**** AWS Macie
_Focused on s3_
Amazon Macie is a data security service that discovers sensitive data (Personnaly Identifiable Infromation ~PII~) by using machine learning and pattern matching, provides visibility into data security risks, and enables automated protection against those risks.

To help you manage the security posture of your organization's Amazon Simple Storage Service (Amazon S3) data estate, Macie provides you with an inventory of your S3 buckets, and automatically evaluates and monitors the buckets for security and access control.

**** Security hub
AWS Security Hub provides a consolidated view of your security status in AWS. Automate security checks, manage security findings, and identify the highest priority security issues across your AWS environment.

Central dashboard for the following:
- GuardDuty
- Inspector
- Macie
- External security tools
- lambda

Example flow:
~AWS Inspector~ detect a vulnerability in a ~AWS EC2~ Generate + share findings in ~AWS security Hub~ and triggers an event on ~AWS EventBridge~ or ~AWS SNS~ which invokes a ~lambda~ or ~step function~ or ~system manager~

**** KMS
AWS Key Management Service (AWS KMS) is an encryption and key management service scaled for the cloud. AWS KMS keys and functionality are used by other AWS services, and you can use them to protect data in your own applications that use AWS.

Can apply policies to keys dictating which users can use said key and what operation
keys can encrypt/decrypt/sign/verify files
kms monitoring: ~AWS cloudtrail~ ~AWS cloudwatch~
data key: encrypt large amount of data. Encrypted data key can be stored in the s3 bucket. We still need the kms key to decrypt the encrypted data key to paintext
imported key:
AWS managed keys: AWS manage them on behalf of us. little control used for services using encryption ~sqs~, ~s3~, ~ebs~

***** Asymmtric KMS keys
It is more secure as two keys are used here- one for encryption and the other for decryption.

Asymmetric KMS Keys represent a mathematically related RSA or elliptic curve (ECC) public and private key pair. The private key never leaves AWS KMS unencrypted. Asymmetric keys are used for digital signature applications such as trusted source code, authentication/authorization tokens, document e-signing, e-commerce transactions, and secure messaging.

Does not support encryption for services like s3, lambda, dynamoDB, etc.

***** Customer managed keys
 Customer managed keys are KMS keys in an AWS account that the customer creates, owns, and manages. The customer has full control over these KMS keys, including establishing and maintaining their key policies, IAM policies, grants, etc. Customer- managed keys do not support =digital signature verification=.

***** Symmetric keys
Security is less as only one key is used for both encryption and decryption purpose.

S3, Lambda, DynamoDB, etc integrate with KMS, and only symmetric encryption KMS key can be used here to encrypt the data. Also, the requirement of having the same 256-bit encryption key to encrypt and decrypt the data indicates a Symmetric KMS Key.

**** CloudHSM
AWS CloudHSM combines the benefits of the AWS cloud with the security of hardware security modules (HSMs). A hardware security module (HSM) is a computing device that processes cryptographic operations and provides secure storage for cryptographic keys.

Central location to encrypt/decrypt data. keys never leave the physical server. AWS manages it for you in the cloud as opposed as you having on prem.

You have full control (not AWS) on the keys. Can use clusters for scalability

**** Certificate manager
AWS Certificate Manager (ACM) handles the complexity of creating, storing, and renewing public and private SSL/TLS X.509 certificates and keys that protect your AWS websites and applications. You can provide certificates for your integrated AWS services either by issuing them directly with ACM or by importing third-party certificates into the ACM management system

Careful you can blow the budget wiht them (form experience)

Can't be used for ~EC2/s3/lambda~. You should use for ~cloudfront~, ~ELB~, ~API Gateway~
region specific

**** Private Certificate authority
AWS Private CA enables creation of private certificate authority (CA) hierarchies, including root and subordinate CAs, without the investment and maintenance costs of operating an on-premises CA

Think of a country waiting to issue their bank notes
_Meant for internal communication only_ not on the internet

**** Secret Manager
AWS Secrets Manager helps you to securely encrypt, store, and retrieve credentials for your databases and other services. Instead of hardcoding credentials in your apps, you can make calls to Secrets Manager to retrieve your credentials whenever needed.
***** Automatic Secret Rotation:
Secrets Manager is ideal if you need automatic secret rotation. For example, rotating database credentials or API keys regularly without manual intervention.

***** Comprehensive Secret Management:
If you have complex secret management needs, like versioning, automatic rotation, or frequent updates to sensitive credentials, Secrets Manager provides a more advanced solution.

***** Detailed Monitoring and Compliance:
Secrets Manager offers detailed audit logging, which can help with compliance standards like GDPR, HIPAA, or SOC 2, and you need to tightly monitor who accesses your secrets.
**** NACL/Security group
Reminder NACL acts at the subnet level while Security group acts at the application level. SG are disable all by default. Each rule only add to the allow. SG rules are merged together e.g. if you have multiple SG for one EC2 they get merged into one.

**** Security Lake
Amazon Security Lake is a fully managed security data lake service. You can use Security Lake to automatically centralize security data from AWS environments, SaaS providers, on premises, cloud sources, and third-party sources into a purpose-built data lake that's stored in your AWS account.

As any lake, it makes a copy of all the data.
collect -> store logs into s3 bucket -> normalilize AWS logs -> query/access data

**** WAF
AWS WAF is a web application firewall that lets you monitor the HTTP(S) requests that are forwarded to your protected web application resources. You can protect the following resource types:

sits behind ~cloudfront~, ~API gateway~, or ~ELB~

**** shield
AWS provides two levels of protection against DDoS attacks: AWS Shield Standard and AWS Shield Advanced. AWS Shield Standard is automatically included at no extra cost beyond what you already pay for AWS WAF and your other AWS services. For _added protection against DDoS attacks_, AWS offers AWS Shield Advanced.

DDos consumes alot of your resources, AWS will not bill you for the resources taxed during the attack. You also get AWS shield response team (SRT)

**** Network Firewall
AWS Network Firewall is a stateful, managed, network firewall and intrusion detection and prevention service for your virtual private cloud (VPC) that you create in Amazon Virtual Private Cloud (Amazon VPC).

has to be in its own subnet and forward traffic to the subnet containing our resources. Must configure the ~route table~ proprely.

traffic comes from the ~IGW~ to the firewal subnet, goes to the firewal endpoint for inspection.

Can make use of a transit gateway so that you do not duplicate the firewall. otherwise its one per VPC.

**** Firewall Manager
AWS Firewall Manager simplifies your administration and maintenance tasks across multiple accounts and resources for a variety of protections, including AWS WAF, AWS Shield Advanced, Amazon VPC security groups and network ACLs, AWS Network Firewall, and Amazon Route 53 Resolver DNS Firewall

kinda like ~control tower~

** TODO Design [0/4]
DEADLINE: <2024-10-13 Sun>
*** TODO Security
*** TODO Reliability
*** TODO Performance
*** TODO Cost-optimization

** TODO Exams [/]
*** Old once a week
*** New 2 of them
DEADLINE: <2024-10-21 Mon>

* Misc
Ensures data is protect both in transit and at rest: use ~AWS KMS~
A healthcare company is planning to migrate its patient data management system to AWS using AWS Application Migration Service (AWS MGN). Given the sensitive nature of patient data, what should the Solutions Architect recommend to ensure data security during the migration process?
